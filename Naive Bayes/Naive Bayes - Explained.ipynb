{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this blog, I will cover:\n",
    "\n",
    "1. What is Naive Bayes\n",
    "2. How it works\n",
    "3. How it is calculated\n",
    "4. Why is it Naive\n",
    "5. How does it get calculated, if we don't know P(B|A)\n",
    "6. How to implement naive bayes classifiers in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. What’s Naive Bayes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](Capture5.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes Algorithm's core is the Bayes Theorem, which is predicting the probability of event happen given one or more than one evidence/features observed.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. How does it work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use some examples to illustrate this formula and different scenario.<br>\n",
    "\n",
    "For example:\n",
    "1. you are a fireman, and you want to predict the chances of fire occurrence when got a call report a smoke<br>\n",
    "2. or you are a botanist, you want to predict the chance of a flower to be Jasmine when you measure the petal width/length<br>\n",
    "3. or you are a cybersecurity staff, you want to predict the chance of email to be a spam when the word - 'Viagra' shows up<br>\n",
    "\n",
    "The smoke, petal width/length, or presence of 'Viagra' in an email are all the 'B' in our formula, which is the known evidence/features.<br>\n",
    "\n",
    "The fire occurrence, flower types, Spam email or not, are all the 'A' in our formula, which is event we are interested to predict.<br>\n",
    "\n",
    "Those three 'when' are the '|' in the formula, which is a conditional term, meaning given what we observed so far, how big is the chance the event will happen?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. How does it get calculated?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we gain some intuitive around Bayes probability theorem, let's dive in how we can calculate the probability we are interested - the P(A|B), by given perfect or not perfect information. We will use the fire&smoke example to demonstrate the calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we diving in, three formulas we will be heavily reused:<br>\n",
    "F1. $P(A|B) = {P(A) * P(B|A)}{P(B)}$<br>\n",
    "F2. $P(A) = P(A) * P(B|A) + P(NOTA) * P(B|NOTA)$<br>\n",
    "F3. $P(A) + P(NOTA) = 1$<br>\n",
    "F4. $P(B,C|A) = P(B|A) * P(C|A)$\n",
    "                                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Perfect Scenario: assume you know every individual component in Bayes Theorem:***<br>\n",
    "\n",
    "$$P(fire|smoke) = \\frac{P(fire) * P(smoke|fire)}{P(smoke)} = \\frac{0.01 * 0.8}{0.2} = 0.04$$<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(fire)$ - the probability of having a fire - is 1%<br>\n",
    "$P(smoke)$ - the probability of seeing a smoke - is 20%<br>\n",
    "$P(smoke|fire)$ - out of 100 fire accident, 80 of them starts with smoke - is 80%<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Not-Perfect Scenario 1: assume you do not know the P(smoke)***<br>\n",
    "\n",
    "$$P(fire|smoke) = \\frac{P(fire) * P(smoke|fire)}{???} = \\frac{0.01 * 0.8}{???}$$\n",
    "\n",
    "What you do know additionally:<br>\n",
    "\n",
    "$P(smoke|not fire)$ - out of 100 normal event, 2 of them has smoke, maybe intense cooking.. - is 2%<br>\n",
    "\n",
    "Based on F2 and F3, <br>\n",
    "$$P(smoke) = P(fire) * P(smoke|fire) + P(not fire) * P(smoke | not fire) = 0.01 * 0.80 + 0.99 * 0.02 = 0.0278 $$<br>\n",
    "\n",
    "Let's plug in: <br>\n",
    "$$P(fire|smoke) = \\frac{P(fire) * P(smoke|fire)}{P(smoke)} = \\frac{0.01 * 0.8}{0.0278} = 0.2878$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Not-Perfect Scenario 2: assume we collect more than one features - smoke and High temp, Oh and you don't know P(smoke|fire) or P(smoke)***<br> \n",
    "\n",
    "$$P(fire|smoke,High temp) = \\frac{P(fire) * P(smoke,High temp|fire)}{P(smoke)} = \\frac{0.01 * ???}{???}$$<br>\n",
    "\n",
    "What we do know additionally:<br>\n",
    "$P(smoke|fire)$ - out of e.g. 100 fire accident, 80 of them starts with smoke - is 80%<br>\n",
    "$P(smoke|not fire)$ - out of 100 normal event, 2 of them has smoke, maybe intense cooking.. - is 2% <br>\n",
    "$P(High temp|fire)$ - out of 100 fire accident, 50 of them starts with high temp - is 50%<br>\n",
    "$P(High temp|not fire)$ - out of 100 normal event, 30 of them has high temp, e.g. A/C failures during summer.. - is 30% <br>\n",
    "\n",
    "\n",
    "Let's leveraged the formula and info we do know!<br>\n",
    "Based on F4:\n",
    "$$P(smoke,High temp|fire) = P(smoke|fire) * P(High temp|fire) = 0.80 * 0.50 = 0.40$$<br>\n",
    "$$P(smoke,High temp |not fire) = P(smoke|not fire) * P(High temp|not fire) = 0.02 * 0.30 = 0.06$$<br>\n",
    "\n",
    "Based on F2:\n",
    "$$P(smoke,High temp) = P(fire) * P(smoke,High temp|fire) + P(not fire) * P(smoke,High temp | not fire) = 0.01 * 0.40 + 0.99 * 0.06 = 0.0634$$<br>\n",
    "\n",
    "Let's plug in those two value into the F1\n",
    "$$P(fire|smoke,High temp) = \\frac{P(fire) * P(smoke|fire,High temp)}{P(smoke)} = \\frac{0.01 * 0.40}{0.0634}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Why Naive Bayes Naive?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hope the above three scenarios give you a taste of leveraging known probability to derive the probability you are interested. You may say - okay this method seems reasonable, why it is called 'Naive'?<br>\n",
    "\n",
    "Remember the last of those four formulas above, which is leveraged when we have more than one features: $P(B,C|A) = P(B|A) * P(C|A)$<br>\n",
    "\n",
    "this formula holds only when features B and feature C are independent, which is almost impossible for many cases.<br>\n",
    "\n",
    "***In other word, when features increase or even just more than one, Naive Bayes naively assume they are independent to each other.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. How does it get calculated, if we just don't know P(B|A)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, you may realize the bulk of the calculation is usually done on the $P(B|A)$.<br>\n",
    "In reality, we not always get a direct answer on what's the value of $P(B|A)$.What do we do? __WE MAKE ASSUMPTIONS!__<br>\n",
    "\n",
    "Three common assumptions on the distribution of the feature:<br>\n",
    "- For continuous features (e.g. 1.234,2.345,3.672): Gaussian Naive Bayes assume features are distributed as Gaussian (normal) distribution. <br>\n",
    "- For discrete features (e.g. 1,2,3): Multinomial Naive Bayes assume features are distributed as Multinomial distribution. like rolling the dice <br>\n",
    "- For binary feature (e.g. presence or not): Bernoulli Naive Bayes assume features are distributed as Bernoulli distribution. like tossing the coin<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Naive Bayes Implementation using Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Library\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB,BernoulliNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian Naive Bayes Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NOT FIRE']\n",
      "['FIRE']\n"
     ]
    }
   ],
   "source": [
    "smoke_density = np.array([[1.120], [2.256], [3.800], [0.768], [0.965], [0.362]])\n",
    "X = smoke_density\n",
    "Y = np.array(['FIRE', 'FIRE', 'FIRE', 'NOT FIRE', 'NOT FIRE', 'NOT FIRE'])\n",
    "clf = GaussianNB()\n",
    "clf.fit(X, Y)\n",
    "\n",
    "print(clf.predict([[0.1]]))\n",
    "print(clf.predict([[2.0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multinomial Naive Bayes Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multinomial Naive Bayes is commonly used in text classification, the features here are the distribution of words frequency. <br>\n",
    "For example, we want to use three words' - \"Free\", \"Viagra\", \"Trial\" - frequency to predict whether an email is a Spam or not \n",
    "\n",
    "Emails = [<br>\n",
    "       [Free Free Viagra Viagra!],<br>\n",
    "       [Viagra for Free.],<br>\n",
    "       [Free Trial Viagra ~],<br>\n",
    "       [Free Nail TRIAL],<br>\n",
    "       [Free Spa or Free Nail polish Trial !!!],<br>\n",
    "       [Top 10 Hiking Trial]])<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Not Spam']\n",
      "['Spam']\n"
     ]
    }
   ],
   "source": [
    "Text_Freq = np.array([[2, 2, 0],\n",
    "[1, 1, 0],\n",
    "[1, 1, 1],\n",
    "[1, 0, 1],\n",
    "[1, 0, 2],\n",
    "[0, 0, 1]])\n",
    "\n",
    "X = Text_Freq\n",
    "Y = np.array(['Spam', 'Spam', 'Spam', 'Not Spam', 'Not Spam', 'Not Spam'])\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X, Y)\n",
    "\n",
    "New_Email = 'Moonnight Trial'\n",
    "print(clf.predict([[0,0,1]]))\n",
    "['Not Spam']\n",
    "\n",
    "New_Email2 = 'Free BitCoins'\n",
    "print(clf.predict([[1,1,0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bernoulli Naive Bayes is commonly used in text classification too, the features here are the distribution of words' presence regardless it's frequency. <br>\n",
    "Let's use the same email list<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Not Spam']\n",
      "['Spam']\n"
     ]
    }
   ],
   "source": [
    "Text_Pres = np.array([[1, 1, 0],\n",
    "       [1, 1, 0],\n",
    "       [1, 1, 1],\n",
    "       [1, 0, 1],\n",
    "       [1, 0, 1],\n",
    "       [0, 0, 1]])\n",
    "       \n",
    "X = Text_Pres\n",
    "Y = np.array(['Spam', 'Spam', 'Spam', 'Not Spam', 'Not Spam', 'Not Spam'])\n",
    "clf = BernoulliNB()\n",
    "clf.fit(X, Y)\n",
    "\n",
    "New_Email = 'Moonnight Trial'\n",
    "print(clf.predict([[0,0,1]]))\n",
    "['Not Spam']\n",
    "\n",
    "New_Email2 = 'Free BitCoins'\n",
    "print(clf.predict([[1,1,0]]))\n",
    "['Spam']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Futher Link:\n",
    "if you are interested to know more about the detail of bernoulli and multinoulli and the difference between, check out the following links:\n",
    "https://geekyisawesome.blogspot.com/2016/12/bernoulli-vs-binomial-vs-multinoulli-vs.html\n",
    "\n",
    "if you are interested to know more about using Naive Bayes on Text Classification, refer the following links:\n",
    "https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
